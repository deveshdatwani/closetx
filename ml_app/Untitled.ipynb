{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54c0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from models.encoder.resnets import vgg_16_cust\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "\n",
    "def get_image(url):\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "    image = transform(Image.open(url)).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_input(i, t):\n",
    "    if True:\n",
    "        idx = i\n",
    "        url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top\"\n",
    "        image_path = os.path.join(url, os.listdir(url)[idx]) \n",
    "        top = get_image(image_path)\n",
    "        _idx = random.randint(0, 10)\n",
    "        if _idx == idx: _idx = random.randint(0, 10)\n",
    "        url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/bottom\"\n",
    "        image_path = os.path.join(url, os.listdir(url)[_idx])\n",
    "        bottom = get_image(image_path)\n",
    "        y = torch.tensor([[0]], dtype=torch.float32)\n",
    "        return top, bottom, y\n",
    "    else:\n",
    "        idx = t\n",
    "        url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top\"\n",
    "        image_path = os.path.join(url, os.listdir(url)[idx]) \n",
    "        top = get_image(image_path)\n",
    "        url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/bottom\"\n",
    "        image_path = os.path.join(url, os.listdir(url)[idx])\n",
    "        bottom = get_image(image_path)\n",
    "        y = torch.tensor([[1]], dtype=torch.float32)\n",
    "        return top, bottom, y\n",
    "     \n",
    "\n",
    "def train():\n",
    "    model = Autoencoder()\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    for j in range(10):\n",
    "        for i in range(80):\n",
    "            k = i\n",
    "            x1, x2, y = get_input(i, k)\n",
    "            opt.zero_grad()\n",
    "            output = model(x1)\n",
    "            loss = criterion(output, y)\n",
    "            print(f\"loss: {loss}\")\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print(f\"one outfit complete -- final loss {loss}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e641cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc5bf8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2468443661928177\n",
      "loss: 0.24675463140010834\n",
      "loss: 0.2466716170310974\n",
      "loss: 0.24658259749412537\n",
      "loss: 0.24652960896492004\n",
      "loss: 0.24644750356674194\n",
      "loss: 0.24628445506095886\n",
      "loss: 0.24628077447414398\n",
      "loss: 0.24611419439315796\n",
      "loss: 0.2461181879043579\n",
      "loss: 0.24601489305496216\n",
      "loss: 0.24595177173614502\n",
      "loss: 0.24588127434253693\n",
      "loss: 0.24574685096740723\n",
      "loss: 0.2456238716840744\n",
      "loss: 0.24544182419776917\n",
      "loss: 0.24528415501117706\n",
      "loss: 0.245184525847435\n",
      "loss: 0.24528056383132935\n",
      "loss: 0.24510948359966278\n",
      "loss: 0.24477718770503998\n",
      "loss: 0.24463674426078796\n",
      "loss: 0.2444021999835968\n",
      "loss: 0.24451425671577454\n",
      "loss: 0.24442847073078156\n",
      "loss: 0.24452334642410278\n",
      "loss: 0.24395497143268585\n",
      "loss: 0.24376434087753296\n",
      "loss: 0.24411770701408386\n",
      "loss: 0.24361959099769592\n",
      "loss: 0.24376118183135986\n",
      "loss: 0.2438732087612152\n",
      "loss: 0.24365223944187164\n",
      "loss: 0.24359670281410217\n",
      "loss: 0.24293693900108337\n",
      "loss: 0.24301806092262268\n",
      "loss: 0.24313761293888092\n",
      "loss: 0.2430487871170044\n",
      "loss: 0.24276837706565857\n",
      "loss: 0.24273867905139923\n",
      "loss: 0.2424888163805008\n",
      "loss: 0.24230621755123138\n",
      "loss: 0.2419450432062149\n",
      "loss: 0.24198566377162933\n",
      "loss: 0.2417583018541336\n",
      "loss: 0.24196016788482666\n",
      "loss: 0.24169015884399414\n",
      "loss: 0.2413758486509323\n",
      "loss: 0.24097788333892822\n",
      "loss: 0.24099788069725037\n",
      "loss: 0.24114294350147247\n",
      "loss: 0.24049502611160278\n",
      "loss: 0.24068915843963623\n",
      "loss: 0.24005252122879028\n",
      "loss: 0.24000605940818787\n",
      "loss: 0.23972375690937042\n",
      "loss: 0.2399011254310608\n",
      "loss: 0.2394232451915741\n",
      "loss: 0.23976096510887146\n",
      "loss: 0.23910407721996307\n",
      "loss: 0.23929822444915771\n",
      "loss: 0.23916345834732056\n",
      "loss: 0.23895668983459473\n",
      "loss: 0.2387479692697525\n",
      "loss: 0.2385748028755188\n",
      "loss: 0.23759320378303528\n",
      "loss: 0.2380218803882599\n",
      "loss: 0.23784829676151276\n",
      "loss: 0.23760640621185303\n",
      "loss: 0.237434983253479\n",
      "loss: 0.23723003268241882\n",
      "loss: 0.23600219190120697\n",
      "loss: 0.23604895174503326\n",
      "loss: 0.23642471432685852\n",
      "loss: 0.23605559766292572\n",
      "loss: 0.2354067862033844\n",
      "loss: 0.23565466701984406\n",
      "loss: 0.23436573147773743\n",
      "loss: 0.2349662035703659\n",
      "loss: 0.23422065377235413\n",
      "one outfit complete -- final loss 0.23422065377235413\n",
      "loss: 0.2344283014535904\n",
      "loss: 0.23434031009674072\n",
      "loss: 0.23392419517040253\n",
      "loss: 0.2336234301328659\n",
      "loss: 0.23318012058734894\n",
      "loss: 0.23284268379211426\n",
      "loss: 0.2323041707277298\n",
      "loss: 0.23230652511119843\n",
      "loss: 0.23138391971588135\n",
      "loss: 0.2313951700925827\n",
      "loss: 0.2312098890542984\n",
      "loss: 0.23061738908290863\n",
      "loss: 0.2301516830921173\n",
      "loss: 0.2296018749475479\n",
      "loss: 0.22933806478977203\n",
      "loss: 0.2282729595899582\n",
      "loss: 0.22741149365901947\n",
      "loss: 0.2271421253681183\n",
      "loss: 0.22705350816249847\n",
      "loss: 0.2266356498003006\n",
      "loss: 0.22534148395061493\n",
      "loss: 0.22467246651649475\n",
      "loss: 0.22382302582263947\n",
      "loss: 0.2240256518125534\n",
      "loss: 0.22343143820762634\n",
      "loss: 0.2241133600473404\n",
      "loss: 0.22182083129882812\n",
      "loss: 0.2210264950990677\n",
      "loss: 0.22144442796707153\n",
      "loss: 0.2198883295059204\n",
      "loss: 0.21987509727478027\n",
      "loss: 0.2205139398574829\n",
      "loss: 0.21900418400764465\n",
      "loss: 0.21896295249462128\n",
      "loss: 0.21646368503570557\n",
      "loss: 0.21689148247241974\n",
      "loss: 0.21603284776210785\n",
      "loss: 0.21681256592273712\n",
      "loss: 0.2146752029657364\n",
      "loss: 0.2138320952653885\n",
      "loss: 0.2126057744026184\n",
      "loss: 0.21218764781951904\n",
      "loss: 0.2104867696762085\n",
      "loss: 0.20984750986099243\n",
      "loss: 0.2093665450811386\n",
      "loss: 0.20914924144744873\n",
      "loss: 0.20846319198608398\n",
      "loss: 0.20647971332073212\n",
      "loss: 0.20526787638664246\n",
      "loss: 0.20461387932300568\n",
      "loss: 0.20422613620758057\n",
      "loss: 0.20260678231716156\n",
      "loss: 0.2018316090106964\n",
      "loss: 0.19985713064670563\n",
      "loss: 0.1995488852262497\n",
      "loss: 0.1979595422744751\n",
      "loss: 0.1974094659090042\n",
      "loss: 0.19595752656459808\n",
      "loss: 0.19537700712680817\n",
      "loss: 0.19382250308990479\n",
      "loss: 0.1940477192401886\n",
      "loss: 0.19185838103294373\n",
      "loss: 0.1917247772216797\n",
      "loss: 0.19051241874694824\n",
      "loss: 0.18971242010593414\n",
      "loss: 0.18642263114452362\n",
      "loss: 0.18692784011363983\n",
      "loss: 0.1850845366716385\n",
      "loss: 0.18373946845531464\n",
      "loss: 0.18363431096076965\n",
      "loss: 0.1815418303012848\n",
      "loss: 0.1793513149023056\n",
      "loss: 0.17840176820755005\n",
      "loss: 0.17743873596191406\n",
      "loss: 0.17731957137584686\n",
      "loss: 0.1749921292066574\n",
      "loss: 0.17352569103240967\n",
      "loss: 0.17120914161205292\n",
      "loss: 0.17110499739646912\n",
      "loss: 0.17032812535762787\n",
      "one outfit complete -- final loss 0.17032812535762787\n",
      "loss: 0.1674998253583908\n",
      "loss: 0.16885289549827576\n",
      "loss: 0.16672271490097046\n",
      "loss: 0.1656891107559204\n",
      "loss: 0.16233962774276733\n",
      "loss: 0.16117660701274872\n",
      "loss: 0.16124415397644043\n",
      "loss: 0.16051270067691803\n",
      "loss: 0.15668269991874695\n",
      "loss: 0.15576395392417908\n",
      "loss: 0.15669097006320953\n",
      "loss: 0.15344811975955963\n",
      "loss: 0.15152417123317719\n",
      "loss: 0.1505986452102661\n",
      "loss: 0.15221387147903442\n",
      "loss: 0.14793479442596436\n",
      "loss: 0.14489296078681946\n",
      "loss: 0.14497482776641846\n",
      "loss: 0.14199326932430267\n",
      "loss: 0.14242087304592133\n",
      "loss: 0.14020399749279022\n",
      "loss: 0.1381607949733734\n",
      "loss: 0.13679610192775726\n",
      "loss: 0.13588076829910278\n",
      "loss: 0.13377496600151062\n",
      "loss: 0.13701842725276947\n",
      "loss: 0.1320953220129013\n",
      "loss: 0.13066020607948303\n",
      "loss: 0.12807440757751465\n",
      "loss: 0.1270936131477356\n",
      "loss: 0.12558633089065552\n",
      "loss: 0.1280631572008133\n",
      "loss: 0.12337842583656311\n",
      "loss: 0.12458209693431854\n",
      "loss: 0.12072491645812988\n",
      "loss: 0.12302596867084503\n",
      "loss: 0.1176721602678299\n",
      "loss: 0.12441740185022354\n",
      "loss: 0.11715329438447952\n",
      "loss: 0.11426857858896255\n",
      "loss: 0.11246801912784576\n",
      "loss: 0.11363614350557327\n",
      "loss: 0.11066335439682007\n",
      "loss: 0.1087953969836235\n",
      "loss: 0.10992608219385147\n",
      "loss: 0.10818072408437729\n",
      "loss: 0.10944807529449463\n",
      "loss: 0.10510751605033875\n",
      "loss: 0.10476290434598923\n",
      "loss: 0.10355214029550552\n",
      "loss: 0.10204299539327621\n",
      "loss: 0.10223448276519775\n",
      "loss: 0.09938647598028183\n",
      "loss: 0.09820420295000076\n",
      "loss: 0.0987589955329895\n",
      "loss: 0.09648334980010986\n",
      "loss: 0.09520678967237473\n",
      "loss: 0.094425268471241\n",
      "loss: 0.09237030893564224\n",
      "loss: 0.09236111491918564\n",
      "loss: 0.09316688030958176\n",
      "loss: 0.08922524750232697\n",
      "loss: 0.09070293605327606\n",
      "loss: 0.09042062610387802\n",
      "loss: 0.09014738351106644\n",
      "loss: 0.0863957554101944\n",
      "loss: 0.08721037954092026\n",
      "loss: 0.08497973531484604\n",
      "loss: 0.0835937112569809\n",
      "loss: 0.08478862792253494\n",
      "loss: 0.08188381046056747\n",
      "loss: 0.08194243162870407\n",
      "loss: 0.080986887216568\n",
      "loss: 0.07890932261943817\n",
      "loss: 0.08134540915489197\n",
      "loss: 0.07903297990560532\n",
      "loss: 0.07645203173160553\n",
      "loss: 0.0761326476931572\n",
      "loss: 0.07619618624448776\n",
      "loss: 0.07703769207000732\n",
      "one outfit complete -- final loss 0.07703769207000732\n",
      "loss: 0.072395920753479\n",
      "loss: 0.07744475454092026\n",
      "loss: 0.07414247840642929\n",
      "loss: 0.07506375014781952\n",
      "loss: 0.069819375872612\n",
      "loss: 0.06938721984624863\n",
      "loss: 0.07208265364170074\n",
      "loss: 0.07136465609073639\n",
      "loss: 0.06739715486764908\n",
      "loss: 0.06669899821281433\n",
      "loss: 0.06968390196561813\n",
      "loss: 0.06610243022441864\n",
      "loss: 0.06452121585607529\n",
      "loss: 0.06473758816719055\n",
      "loss: 0.06968807429075241\n",
      "loss: 0.06433483958244324\n",
      "loss: 0.06141727417707443\n",
      "loss: 0.06265228986740112\n",
      "loss: 0.05949285253882408\n",
      "loss: 0.06114707514643669\n",
      "loss: 0.05997679755091667\n",
      "loss: 0.05860856920480728\n",
      "loss: 0.05814056470990181\n",
      "loss: 0.05765834450721741\n",
      "loss: 0.056250590831041336\n",
      "loss: 0.0619836263358593\n",
      "loss: 0.05652381107211113\n",
      "loss: 0.05585115775465965\n",
      "loss: 0.053454939275979996\n",
      "loss: 0.053677067160606384\n",
      "loss: 0.052702561020851135\n",
      "loss: 0.05594860762357712\n",
      "loss: 0.051780324429273605\n",
      "loss: 0.05387173965573311\n",
      "loss: 0.051133107393980026\n",
      "loss: 0.05481453984975815\n",
      "loss: 0.04922856017947197\n",
      "loss: 0.059076134115457535\n",
      "loss: 0.050544701516628265\n",
      "loss: 0.04800902679562569\n",
      "loss: 0.047147128731012344\n",
      "loss: 0.04921738803386688\n",
      "loss: 0.04688071087002754\n",
      "loss: 0.04570995271205902\n",
      "loss: 0.047498080879449844\n",
      "loss: 0.046158477663993835\n",
      "loss: 0.04881047084927559\n",
      "loss: 0.044740717858076096\n",
      "loss: 0.045021072030067444\n",
      "loss: 0.044547904282808304\n",
      "loss: 0.04343746602535248\n",
      "loss: 0.04451930895447731\n",
      "loss: 0.04223104566335678\n",
      "loss: 0.04189050570130348\n",
      "loss: 0.04292900860309601\n",
      "loss: 0.041431888937950134\n",
      "loss: 0.04077034071087837\n",
      "loss: 0.04053948074579239\n",
      "loss: 0.039142951369285583\n",
      "loss: 0.039700258523225784\n",
      "loss: 0.04087212309241295\n",
      "loss: 0.03784346953034401\n",
      "loss: 0.03948040306568146\n",
      "loss: 0.04057683050632477\n",
      "loss: 0.04079262912273407\n",
      "loss: 0.03721509501338005\n",
      "loss: 0.038340602070093155\n",
      "loss: 0.037042416632175446\n",
      "loss: 0.03615187481045723\n",
      "loss: 0.037496987730264664\n",
      "loss: 0.035264331847429276\n",
      "loss: 0.035783734172582626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03539663925766945\n",
      "loss: 0.033920127898454666\n",
      "loss: 0.03699047118425369\n",
      "loss: 0.034880559891462326\n",
      "loss: 0.032951924949884415\n",
      "loss: 0.03309923782944679\n",
      "loss: 0.03387068212032318\n",
      "loss: 0.034595053642988205\n",
      "one outfit complete -- final loss 0.034595053642988205\n",
      "loss: 0.03098972514271736\n",
      "loss: 0.03710952401161194\n",
      "loss: 0.0333327017724514\n",
      "loss: 0.03547406196594238\n",
      "loss: 0.030095288529992104\n",
      "loss: 0.0300260279327631\n",
      "loss: 0.0331474244594574\n",
      "loss: 0.03252091631293297\n",
      "loss: 0.029313502833247185\n",
      "loss: 0.028963623568415642\n",
      "loss: 0.032089732587337494\n",
      "loss: 0.029119277372956276\n",
      "loss: 0.027991443872451782\n",
      "loss: 0.028477350249886513\n",
      "loss: 0.03406543657183647\n",
      "loss: 0.028817294165492058\n",
      "loss: 0.026512617245316505\n",
      "loss: 0.027727458626031876\n",
      "loss: 0.025499632582068443\n",
      "loss: 0.027055377140641212\n",
      "loss: 0.026209747418761253\n",
      "loss: 0.02537485398352146\n",
      "loss: 0.025170868262648582\n",
      "loss: 0.025070900097489357\n",
      "loss: 0.024237701669335365\n",
      "loss: 0.0303066223859787\n",
      "loss: 0.024746134877204895\n",
      "loss: 0.024371884763240814\n",
      "loss: 0.022867605090141296\n",
      "loss: 0.023154407739639282\n",
      "loss: 0.02264207974076271\n",
      "loss: 0.025545930489897728\n",
      "loss: 0.022294100373983383\n",
      "loss: 0.024227963760495186\n",
      "loss: 0.022091524675488472\n",
      "loss: 0.025613991543650627\n",
      "loss: 0.021052340045571327\n",
      "loss: 0.030586637556552887\n",
      "loss: 0.02262076921761036\n",
      "loss: 0.020612532272934914\n",
      "loss: 0.02012675069272518\n",
      "loss: 0.021961558610200882\n",
      "loss: 0.0202048197388649\n",
      "loss: 0.01950688846409321\n",
      "loss: 0.02098718471825123\n",
      "loss: 0.02018805965781212\n",
      "loss: 0.022748658433556557\n",
      "loss: 0.019348666071891785\n",
      "loss: 0.019645733758807182\n",
      "loss: 0.01950613409280777\n",
      "loss: 0.018821170553565025\n",
      "loss: 0.019779538735747337\n",
      "loss: 0.01819252409040928\n",
      "loss: 0.018040882423520088\n",
      "loss: 0.018961118534207344\n",
      "loss: 0.018026238307356834\n",
      "loss: 0.01766705885529518\n",
      "loss: 0.017572078853845596\n",
      "loss: 0.016710570082068443\n",
      "loss: 0.017222024500370026\n",
      "loss: 0.01838156022131443\n",
      "loss: 0.016131451353430748\n",
      "loss: 0.017507385462522507\n",
      "loss: 0.01912352815270424\n",
      "loss: 0.01948731206357479\n",
      "loss: 0.016102466732263565\n",
      "loss: 0.017232978716492653\n",
      "loss: 0.01641782559454441\n",
      "loss: 0.015858545899391174\n",
      "loss: 0.01699860394001007\n",
      "loss: 0.015303882770240307\n",
      "loss: 0.015731150284409523\n",
      "loss: 0.015603500418365002\n",
      "loss: 0.014650944620370865\n",
      "loss: 0.01760323904454708\n",
      "loss: 0.01559539046138525\n",
      "loss: 0.014277405105531216\n",
      "loss: 0.014440501108765602\n",
      "loss: 0.015428283251821995\n",
      "loss: 0.01583743281662464\n",
      "one outfit complete -- final loss 0.01583743281662464\n",
      "loss: 0.013260659761726856\n",
      "loss: 0.019381528720259666\n",
      "loss: 0.01550037320703268\n",
      "loss: 0.01807837188243866\n",
      "loss: 0.013020467944443226\n",
      "loss: 0.013071972876787186\n",
      "loss: 0.015933819115161896\n",
      "loss: 0.015400678850710392\n",
      "loss: 0.01283264346420765\n",
      "loss: 0.012683388777077198\n",
      "loss: 0.015471834689378738\n",
      "loss: 0.01307355985045433\n",
      "loss: 0.012244533747434616\n",
      "loss: 0.012740652076900005\n",
      "loss: 0.018091734498739243\n",
      "loss: 0.01324309129267931\n",
      "loss: 0.01149303000420332\n",
      "loss: 0.012468169443309307\n",
      "loss: 0.010975251905620098\n",
      "loss: 0.012250733561813831\n",
      "loss: 0.011576547287404537\n",
      "loss: 0.011072486639022827\n",
      "loss: 0.010978564620018005\n",
      "loss: 0.01103788148611784\n",
      "loss: 0.010549976490437984\n",
      "loss: 0.016282211989164352\n",
      "loss: 0.011004931293427944\n",
      "loss: 0.010784585028886795\n",
      "loss: 0.009894108399748802\n",
      "loss: 0.010115218348801136\n",
      "loss: 0.00986425206065178\n",
      "loss: 0.012258095666766167\n",
      "loss: 0.009776155464351177\n",
      "loss: 0.011385146528482437\n",
      "loss: 0.009712077677249908\n",
      "loss: 0.012717096135020256\n",
      "loss: 0.009176992811262608\n",
      "loss: 0.017578255385160446\n",
      "loss: 0.010633322410285473\n",
      "loss: 0.009066371247172356\n",
      "loss: 0.008783948607742786\n",
      "loss: 0.010225065052509308\n",
      "loss: 0.008936122059822083\n",
      "loss: 0.008533886633813381\n",
      "loss: 0.009626285172998905\n",
      "loss: 0.0091965701431036\n",
      "loss: 0.011366096325218678\n",
      "loss: 0.008651534095406532\n",
      "loss: 0.008876564912497997\n",
      "loss: 0.008888776414096355\n",
      "loss: 0.008485049940645695\n",
      "loss: 0.00921247061342001\n",
      "loss: 0.008146882988512516\n",
      "loss: 0.008058878593146801\n",
      "loss: 0.00876991730183363\n",
      "loss: 0.008200723677873611\n",
      "loss: 0.008010070770978928\n",
      "loss: 0.007954851724207401\n",
      "loss: 0.007448509335517883\n",
      "loss: 0.00782572478055954\n",
      "loss: 0.008837399072945118\n",
      "loss: 0.007199092768132687\n",
      "loss: 0.008256038650870323\n",
      "loss: 0.010039514862000942\n",
      "loss: 0.01044261734932661\n",
      "loss: 0.007324303034693003\n",
      "loss: 0.008332383818924427\n",
      "loss: 0.0078111812472343445\n",
      "loss: 0.007468024268746376\n",
      "loss: 0.00833898689597845\n",
      "loss: 0.0070603033527731895\n",
      "loss: 0.007336486130952835\n",
      "loss: 0.007327931933104992\n",
      "loss: 0.006733954884111881\n",
      "loss: 0.009380927309393883\n",
      "loss: 0.007486581802368164\n",
      "loss: 0.0066113159991800785\n",
      "loss: 0.006710768211632967\n",
      "loss: 0.007703939452767372\n",
      "loss: 0.007842487655580044\n",
      "one outfit complete -- final loss 0.007842487655580044\n",
      "loss: 0.006061147898435593\n",
      "loss: 0.011815246194601059\n",
      "loss: 0.007992591708898544\n",
      "loss: 0.010671436786651611\n",
      "loss: 0.006061348598450422\n",
      "loss: 0.006138910539448261\n",
      "loss: 0.0085901552811265\n",
      "loss: 0.00812521856278181\n",
      "loss: 0.006071006879210472\n",
      "loss: 0.006018372252583504\n",
      "loss: 0.008377807214856148\n",
      "loss: 0.006443824153393507\n",
      "loss: 0.005810597911477089\n",
      "loss: 0.006240067072212696\n",
      "loss: 0.01111020240932703\n",
      "loss: 0.006712121423333883\n",
      "loss: 0.005388426128774881\n",
      "loss: 0.006112310569733381\n",
      "loss: 0.005126047879457474\n",
      "loss: 0.006115081254392862\n",
      "loss: 0.00555199570953846\n",
      "loss: 0.005241568200290203\n",
      "loss: 0.005187340546399355\n",
      "loss: 0.005295648239552975\n",
      "loss: 0.005005958024412394\n",
      "loss: 0.010230042971670628\n",
      "loss: 0.005336851812899113\n",
      "loss: 0.005192824173718691\n",
      "loss: 0.00468089384958148\n",
      "loss: 0.004818003159016371\n",
      "loss: 0.004701859783381224\n",
      "loss: 0.006624037399888039\n",
      "loss: 0.004708243999630213\n",
      "loss: 0.00600117351859808\n",
      "loss: 0.004668313544243574\n",
      "loss: 0.0071368347853422165\n",
      "loss: 0.004397524520754814\n",
      "loss: 0.011598696932196617\n",
      "loss: 0.005647988989949226\n",
      "loss: 0.004396370612084866\n",
      "loss: 0.004220018163323402\n",
      "loss: 0.005304219201207161\n",
      "loss: 0.00434865290299058\n",
      "loss: 0.004114147741347551\n",
      "loss: 0.004884651396423578\n",
      "loss: 0.004674208350479603\n",
      "loss: 0.006436194758862257\n",
      "loss: 0.004275704734027386\n",
      "loss: 0.004422956146299839\n",
      "loss: 0.00448961416259408\n",
      "loss: 0.004250062629580498\n",
      "loss: 0.00477510504424572\n",
      "loss: 0.004047991242259741\n",
      "loss: 0.003978218883275986\n",
      "loss: 0.004498047288507223\n",
      "loss: 0.004149021115154028\n",
      "loss: 0.004040395841002464\n",
      "loss: 0.003991817124187946\n",
      "loss: 0.003693904960528016\n",
      "loss: 0.003948325291275978\n",
      "loss: 0.004795215558260679\n",
      "loss: 0.003577945986762643\n",
      "loss: 0.0043721068650484085\n",
      "loss: 0.006162603385746479\n",
      "loss: 0.006561947055160999\n",
      "loss: 0.0036978814750909805\n",
      "loss: 0.004562355112284422\n",
      "loss: 0.004203213844448328\n",
      "loss: 0.003996709361672401\n",
      "loss: 0.0046411678194999695\n",
      "loss: 0.00364939053542912\n",
      "loss: 0.0038044541142880917\n",
      "loss: 0.0038403086364269257\n",
      "loss: 0.0034667057916522026\n",
      "loss: 0.005815026815980673\n",
      "loss: 0.004023024812340736\n",
      "loss: 0.003435953054577112\n",
      "loss: 0.0034742176067084074\n",
      "loss: 0.004386581480503082\n",
      "loss: 0.004346579313278198\n",
      "one outfit complete -- final loss 0.004346579313278198\n",
      "loss: 0.003105392912402749\n",
      "loss: 0.008432216010987759\n",
      "loss: 0.004736071452498436\n",
      "loss: 0.007362766191363335\n",
      "loss: 0.0031730597838759422\n",
      "loss: 0.003244652645662427\n",
      "loss: 0.005316344555467367\n",
      "loss: 0.004912682808935642\n",
      "loss: 0.0032250534277409315\n",
      "loss: 0.00321740610525012\n",
      "loss: 0.005211983807384968\n",
      "loss: 0.0036130158696323633\n",
      "loss: 0.003104499774053693\n",
      "loss: 0.0034615315962582827\n",
      "loss: 0.007858392782509327\n",
      "loss: 0.0038509077858179808\n",
      "loss: 0.002830469748005271\n",
      "loss: 0.003357088193297386\n",
      "loss: 0.0026934868656098843\n",
      "loss: 0.003462908323854208\n",
      "loss: 0.0029759961180388927\n",
      "loss: 0.0027767072897404432\n",
      "loss: 0.0027374199125915766\n",
      "loss: 0.002848853822797537\n",
      "loss: 0.002669933019205928\n",
      "loss: 0.007429432589560747\n",
      "loss: 0.0028934914153069258\n",
      "loss: 0.0027901283465325832\n",
      "loss: 0.002494943095371127\n",
      "loss: 0.0025707301683723927\n",
      "loss: 0.0025197777431458235\n",
      "loss: 0.004084113519638777\n",
      "loss: 0.0025557337794452906\n",
      "loss: 0.003605116857215762\n",
      "loss: 0.0025118107441812754\n",
      "loss: 0.00453867157921195\n",
      "loss: 0.002374708652496338\n",
      "loss: 0.0085629653185606\n",
      "loss: 0.003439957508817315\n",
      "loss: 0.0024029421620070934\n",
      "loss: 0.0022828439250588417\n",
      "loss: 0.0030977968126535416\n",
      "loss: 0.0023736057337373495\n",
      "loss: 0.0022321464493870735\n",
      "loss: 0.0027736856136471033\n",
      "loss: 0.0026917648501694202\n",
      "loss: 0.004115029238164425\n",
      "loss: 0.00237096706405282\n",
      "loss: 0.002461675787344575\n",
      "loss: 0.0025413120165467262\n",
      "loss: 0.0023989526089280844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0027763638645410538\n",
      "loss: 0.0022636002395302057\n",
      "loss: 0.0021995222195982933\n",
      "loss: 0.0025759392883628607\n",
      "loss: 0.002360312035307288\n",
      "loss: 0.002289380645379424\n",
      "loss: 0.0022422345355153084\n",
      "loss: 0.0020639027934521437\n",
      "loss: 0.0022305368911474943\n",
      "loss: 0.002941502956673503\n",
      "loss: 0.0020028359722346067\n",
      "loss: 0.0026100166141986847\n",
      "loss: 0.004347617272287607\n",
      "loss: 0.004731538239866495\n",
      "loss: 0.0020864091347903013\n",
      "loss: 0.00282812537625432\n",
      "loss: 0.0025549433194100857\n",
      "loss: 0.0024397505912929773\n",
      "loss: 0.002920379163697362\n",
      "loss: 0.0021225744858384132\n",
      "loss: 0.002197015332058072\n",
      "loss: 0.002245795913040638\n",
      "loss: 0.002006624359637499\n",
      "loss: 0.004112101625651121\n",
      "loss: 0.0024098048452287912\n",
      "loss: 0.0020082436967641115\n",
      "loss: 0.0020047544967383146\n",
      "loss: 0.002815354149788618\n",
      "loss: 0.0026721928734332323\n",
      "one outfit complete -- final loss 0.0026721928734332323\n",
      "loss: 0.001787527115084231\n",
      "loss: 0.006725669372826815\n",
      "loss: 0.0031799625139683485\n",
      "loss: 0.005696255713701248\n",
      "loss: 0.0018663969822227955\n",
      "loss: 0.0019261958077549934\n",
      "loss: 0.003689397359266877\n",
      "loss: 0.0033441416453570127\n",
      "loss: 0.00191471166908741\n",
      "loss: 0.0019299278501421213\n",
      "loss: 0.003643676172941923\n",
      "loss: 0.0022839198354631662\n",
      "loss: 0.0018587189260870218\n",
      "loss: 0.002156392438337207\n",
      "loss: 0.0061516775749623775\n",
      "loss: 0.0024639826733618975\n",
      "loss: 0.0016586477868258953\n",
      "loss: 0.0020441433880478144\n",
      "loss: 0.0015849695773795247\n",
      "loss: 0.002198584144935012\n",
      "loss: 0.001769069116562605\n",
      "loss: 0.0016359779983758926\n",
      "loss: 0.0016044117510318756\n",
      "loss: 0.0017040256643667817\n",
      "loss: 0.0015883018495514989\n",
      "loss: 0.005966426804661751\n",
      "loss: 0.0017365835374221206\n",
      "loss: 0.0016581341624259949\n",
      "loss: 0.0014854359906166792\n",
      "loss: 0.0015233043814077973\n",
      "loss: 0.0015034188982099295\n",
      "loss: 0.0028068567626178265\n",
      "loss: 0.0015463754534721375\n",
      "loss: 0.00241740420460701\n",
      "loss: 0.0014970209449529648\n",
      "loss: 0.003182029351592064\n",
      "loss: 0.0014282200718298554\n",
      "loss: 0.006807193625718355\n",
      "loss: 0.002348894253373146\n",
      "loss: 0.001460676547139883\n",
      "loss: 0.001372701139189303\n",
      "loss: 0.0019947190303355455\n",
      "loss: 0.001433181925676763\n",
      "loss: 0.001344504184089601\n",
      "loss: 0.0017308959504589438\n",
      "loss: 0.0017239459557458758\n",
      "loss: 0.0028831243980675936\n",
      "loss: 0.0014510785695165396\n",
      "loss: 0.001505793072283268\n",
      "loss: 0.0015824896981939673\n",
      "loss: 0.0014987721806392074\n",
      "loss: 0.0017754107248038054\n",
      "loss: 0.0013998367357999086\n",
      "loss: 0.0013399809831753373\n",
      "loss: 0.0016151395393535495\n",
      "loss: 0.0014821098884567618\n",
      "loss: 0.0014284673379734159\n",
      "loss: 0.0013840572210028768\n",
      "loss: 0.001274873036891222\n",
      "loss: 0.0013839469756931067\n",
      "loss: 0.001988449599593878\n",
      "loss: 0.001238310826011002\n",
      "loss: 0.00171524693723768\n",
      "loss: 0.003381401998922229\n",
      "loss: 0.0037490190006792545\n",
      "loss: 0.0012904350878670812\n",
      "loss: 0.0019326051697134972\n",
      "loss: 0.001706780050881207\n",
      "loss: 0.0016553368186578155\n",
      "loss: 0.002019682200625539\n",
      "loss: 0.001357672968879342\n",
      "loss: 0.001383490045554936\n",
      "loss: 0.0014326346572488546\n",
      "loss: 0.0012762508122250438\n",
      "loss: 0.003191324882209301\n",
      "loss: 0.0015696975169703364\n",
      "loss: 0.0012888346100226045\n",
      "loss: 0.0012615241575986147\n",
      "loss: 0.0019726890604943037\n",
      "loss: 0.0017762123607099056\n",
      "one outfit complete -- final loss 0.0017762123607099056\n",
      "loss: 0.001129030715674162\n",
      "loss: 0.005731427576392889\n",
      "loss: 0.0023394429590553045\n",
      "loss: 0.004728824365884066\n",
      "loss: 0.001202965504489839\n",
      "loss: 0.001251955982297659\n",
      "loss: 0.0027713861782103777\n",
      "loss: 0.002479074290022254\n",
      "loss: 0.0012384309666231275\n",
      "loss: 0.001265302998945117\n",
      "loss: 0.002764325123280287\n",
      "loss: 0.001580870826728642\n",
      "loss: 0.0012148034293204546\n",
      "loss: 0.001467031193897128\n",
      "loss: 0.005131471902132034\n",
      "loss: 0.0017073055496439338\n",
      "loss: 0.0010581531096249819\n",
      "loss: 0.0013446913799270988\n",
      "loss: 0.0010175786446779966\n",
      "loss: 0.0015205689705908298\n",
      "loss: 0.0011381424264982343\n",
      "loss: 0.001046297955326736\n",
      "loss: 0.001020299969241023\n",
      "loss: 0.0011048426385968924\n",
      "loss: 0.001026865909807384\n",
      "loss: 0.005095571279525757\n",
      "loss: 0.0011261107865720987\n",
      "loss: 0.0010648733004927635\n",
      "loss: 0.0009622016223147511\n",
      "loss: 0.0009785245638340712\n",
      "loss: 0.0009733949555084109\n",
      "loss: 0.002083703875541687\n",
      "loss: 0.0010158478980883956\n",
      "loss: 0.0017552230274304748\n",
      "loss: 0.000965168874245137\n",
      "loss: 0.0023866789415478706\n",
      "loss: 0.0009321643155999482\n",
      "loss: 0.0056651621125638485\n",
      "loss: 0.0017430640291422606\n",
      "loss: 0.0009622366051189601\n",
      "loss: 0.0008945294539444149\n",
      "loss: 0.001378441578708589\n",
      "loss: 0.0009344955906271935\n",
      "loss: 0.0008769694250077009\n",
      "loss: 0.001158299739472568\n",
      "loss: 0.0011951805790886283\n",
      "loss: 0.0021501989103853703\n",
      "loss: 0.0009565715445205569\n",
      "loss: 0.0009893779642879963\n",
      "loss: 0.0010579617228358984\n",
      "loss: 0.0010105273686349392\n",
      "loss: 0.0012190471170470119\n",
      "loss: 0.0009340614196844399\n",
      "loss: 0.0008790807332843542\n",
      "loss: 0.0010833480628207326\n",
      "loss: 0.0010029670083895326\n",
      "loss: 0.0009576639859005809\n",
      "loss: 0.0009174587903544307\n",
      "loss: 0.000849389296490699\n",
      "loss: 0.0009214083547703922\n",
      "loss: 0.001442653825506568\n",
      "loss: 0.0008252518018707633\n",
      "loss: 0.0012099947780370712\n",
      "loss: 0.002801312366500497\n",
      "loss: 0.003154521808028221\n",
      "loss: 0.000855889345984906\n",
      "loss: 0.0014179680729284883\n",
      "loss: 0.001219934318214655\n",
      "loss: 0.0012147404486313462\n",
      "loss: 0.0014953542267903686\n",
      "loss: 0.0009324309648945928\n",
      "loss: 0.0009300109813921154\n",
      "loss: 0.0009750872850418091\n",
      "loss: 0.0008711861446499825\n",
      "loss: 0.002635464770719409\n",
      "loss: 0.001087232492864132\n",
      "loss: 0.000887139409314841\n",
      "loss: 0.0008476126822642982\n",
      "loss: 0.0014693523989990354\n",
      "loss: 0.0012494451366364956\n",
      "one outfit complete -- final loss 0.0012494451366364956\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6531100273132324\n",
      "Epoch 2, Loss: 2.3017611503601074\n",
      "Epoch 3, Loss: 2.3277623653411865\n",
      "Epoch 4, Loss: 2.221745491027832\n",
      "Epoch 5, Loss: 2.0449509620666504\n",
      "Epoch 6, Loss: 1.952418565750122\n",
      "Epoch 7, Loss: 1.8139450550079346\n",
      "Epoch 8, Loss: 1.7668697834014893\n",
      "Epoch 9, Loss: 1.687452793121338\n",
      "Epoch 10, Loss: 1.802872657775879\n",
      "Epoch 11, Loss: 1.778734803199768\n",
      "Epoch 12, Loss: 1.9847614765167236\n",
      "Epoch 13, Loss: 1.729601263999939\n",
      "Epoch 14, Loss: 2.0193138122558594\n",
      "Epoch 15, Loss: 1.7830737829208374\n",
      "Epoch 16, Loss: 1.549887776374817\n",
      "Epoch 17, Loss: 1.8973757028579712\n",
      "Epoch 18, Loss: 1.815845012664795\n",
      "Epoch 19, Loss: 1.6292678117752075\n",
      "Epoch 20, Loss: 1.9873770475387573\n",
      "Epoch 21, Loss: 1.7281038761138916\n",
      "Epoch 22, Loss: 1.6730481386184692\n",
      "Epoch 23, Loss: 1.5516939163208008\n",
      "Epoch 24, Loss: 1.6586358547210693\n",
      "Epoch 25, Loss: 1.648184061050415\n",
      "Epoch 26, Loss: 1.6149046421051025\n",
      "Epoch 27, Loss: 1.7804019451141357\n",
      "Epoch 28, Loss: 1.6438164710998535\n",
      "Epoch 29, Loss: 1.6986974477767944\n",
      "Epoch 30, Loss: 1.540252923965454\n",
      "Epoch 31, Loss: 1.7242295742034912\n",
      "Epoch 32, Loss: 1.4193594455718994\n",
      "Epoch 33, Loss: 1.4708386659622192\n",
      "Epoch 34, Loss: 1.6732237339019775\n",
      "Epoch 35, Loss: 1.656862497329712\n",
      "Epoch 36, Loss: 1.5455087423324585\n",
      "Epoch 37, Loss: 1.8226968050003052\n",
      "Epoch 38, Loss: 1.5179234743118286\n",
      "Epoch 39, Loss: 1.4523825645446777\n",
      "Epoch 40, Loss: 1.3927512168884277\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset class\n",
    "class TShirtDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if self.transform:\n",
    "            return self.transform(image), self.transform(image)  # Two views\n",
    "        return image, image\n",
    "\n",
    "# Define augmentations\n",
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# SimCLR-style model with contrastive loss\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim=128):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.encoder.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "        self.encoder.fc = nn.Identity()  # Remove classification head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projector(features)\n",
    "        return projections\n",
    "\n",
    "# Contrastive loss\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        # Normalize embeddings\n",
    "        z_i = nn.functional.normalize(z_i, dim=1)\n",
    "        z_j = nn.functional.normalize(z_j, dim=1)\n",
    "\n",
    "        # Compute similarity\n",
    "        similarities = torch.mm(z_i, z_j.T) / self.temperature\n",
    "        labels = torch.arange(z_i.size(0)).to(z_i.device)\n",
    "        loss = self.criterion(similarities, labels)\n",
    "        return loss\n",
    "\n",
    "# Prepare data\n",
    "url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top\"\n",
    "images = [Image.open(os.path.join(url, os.listdir(url)[i])) for i in range(80)]  # Replace with actual paths\n",
    "dataset = TShirtDataset(images, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize model and training components\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimCLR(base_encoder=resnet18(pretrained=True)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = NTXentLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    for img1, img2 in dataloader:\n",
    "        img1, img2 = img1.to(device), img2.to(device)\n",
    "        z1, z2 = model(img1), model(img2)\n",
    "        loss = criterion(z1, z2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af82b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7\n",
    "url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top\"\n",
    "top_path = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top/cn55717004.jpg\"\n",
    "top_image = get_image(top_path)\n",
    "\n",
    "xx = model.encoder(top_image).flatten()\n",
    "\n",
    "url = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top\"\n",
    "top_path = \"/home/deveshdatwani/closetx/ml_app/models/dataset/positive/top/cn56940235.jpg\"\n",
    "top_image = get_image(top_path)\n",
    "\n",
    "yy = model.encoder(top_image).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1279125",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f68a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7240, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c448c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
